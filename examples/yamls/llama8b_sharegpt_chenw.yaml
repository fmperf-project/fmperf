# LMBenchmark Workload Specification Example
# This specification is used for running benchmarks with the LMBenchmark container
model_name: "meta-llama/Llama-3.1-8B-Instruct"  # Model identifier
scenarios: "sharegpt"  # Scenarios to run (all, or sharegpt, long-input, short-input)
# sharegpt: 0.5 0.67 0.84 1 1.17 1.34
# long-input: 1.1 0.9 0.7 0.5 0.3 0.1
# short-input: 0.5 1 2 5 10
qps_values: "0.5 0.67 0.84 1 1.17 1.34 1.51 1.68 1.85 2.02 2.19 2.36 2.53 2.7 2.87 3.04"  # Space-separated list of QPS values to test
# qps_values: "1.34"
image: "quay.io/chenw615/lmbenchmark:completionapi"  # Container image to use
service_account: "default"  # Service account to use for the job 
