# LMBenchmark Workload Specification Example
# This specification is used for running benchmarks with the LMBenchmark container
model_name: "RedHatAI/Llama-4-Scout-17B-16E-Instruct-FP8-dynamic"  # Model identifier
scenarios: "long-input"  # Scenarios to run (all, or sharegpt, long-input, short-input)
qps_values: "0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 2.2 2.4 2.6 2.8 3 3.2 3.4 3.6 3.8 4"  # Space-separated list of QPS values to test
image: "quay.io/mimehta/lmbenchmark:longshortconfig"  # Container image to use
service_account: "default"  # Service account to use for the job 