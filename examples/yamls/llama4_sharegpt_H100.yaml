# LMBenchmark Workload Specification Example
# This specification is used for running benchmarks with the LMBenchmark container
model_name: "RedHatAI/Llama-4-Scout-17B-16E-Instruct-FP8-dynamic"  # Model identifier
scenarios: "sharegpt"  # Scenarios to run (all, or sharegpt, long-input, short-input)
qps_values: "0.1 0.25 0.5 1 2 3 4 5 7.5 10 15 20 40"  # Space-separated list of QPS values to test
image: "quay.io/mimehta/lmbenchmark:longshortconfig"  # Container image to use
service_account: "default"  # Service account to use for the job 
